#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
05_manual_curator.py â€” äººå·¥è¾…åŠ©å‡ºé¢˜å·¥å…· (Human-in-the-Loop)
åŠŸèƒ½ï¼š
 1. éšæœºè¯»å– cleaned_sac/ ä¸‹çš„æ³•å¾‹åˆ‡ç‰‡ã€‚
 2. å±å¹•å±•ç¤ºï¼šæ³•åŸŸã€æ–‡æ¡£åã€SACæ‘˜è¦ã€åˆ‡ç‰‡åŸæ–‡ã€‚
 3. æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„é—®é¢˜ (Question)ã€‚
 4. è‡ªåŠ¨ç”Ÿæˆæ ‡å‡†åŒ–çš„ JSON æµ‹è¯•æ¡ç›® (åŒ…å«ç»å¯¹æ­£ç¡®çš„ gold_sources)ã€‚
 5. ç›®æ ‡ï¼šå¿«é€Ÿæ„å»º 35 ä¸ªé«˜è´¨é‡çš„é»„é‡‘æµ‹è¯•é¢˜ (Gold Standard)ã€‚
"""

import os
import json
import random
import glob

# ====== é…ç½® ======
SRC_DIR = "cleaned_sac"
OUTPUT_FILE = os.path.join("tests", "manual", "test_set_manual_35.json")
TARGET_COUNT = 35  # ç›®æ ‡é¢˜ç›®æ•°é‡

def load_random_chunk():
    """ä»æ‰€æœ‰ .jsonl æ–‡ä»¶ä¸­éšæœºæŠ½å–ä¸€ä¸ªåˆ‡ç‰‡"""
    files = glob.glob(os.path.join(SRC_DIR, "*.jsonl"))
    if not files:
        print(f"âŒ é”™è¯¯: {SRC_DIR} ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° .jsonl æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œ 01 è„šæœ¬ã€‚")
        return None, None

    # éšæœºé€‰æ–‡ä»¶
    target_file = random.choice(files)
    doc_id = os.path.basename(target_file).replace(".jsonl", "")
    
    # è¯»å–æ–‡ä»¶ä¸­çš„æ‰€æœ‰è¡Œ
    chunks = []
    with open(target_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                chunks.append(json.loads(line))
    
    if not chunks:
        return None, None

    # éšæœºé€‰åˆ‡ç‰‡
    chunk = random.choice(chunks)
    return doc_id, chunk

def save_entry(entry, filepath):
    """è¿½åŠ ä¿å­˜åˆ° JSON æ–‡ä»¶"""
    data = []
    if os.path.exists(filepath):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError:
            pass # æ–‡ä»¶æŸåæˆ–ä¸ºç©ºï¼Œè¦†ç›–
    
    data.append(entry)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def main():
    print("\n" + "="*60)
    print("ğŸ‘¨â€ğŸ«  äººå·¥å‡ºé¢˜è¾…åŠ©ç³»ç»Ÿ (Manual Curator)")
    print(f"ç›®æ ‡: æ„å»º {TARGET_COUNT} ä¸ªé»„é‡‘æµ‹è¯•é¢˜")
    print("æ“ä½œ: ç³»ç»Ÿå±•ç¤ºæ³•æ¡ -> ä½ è¾“å…¥é—®é¢˜ -> è‡ªåŠ¨ä¿å­˜")
    print("æç¤º: è¾“å…¥ 's' è·³è¿‡å½“å‰æ®µè½, 'q' ä¿å­˜é€€å‡º")
    print("="*60 + "\n")

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

    current_count = 0
    if os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            try:
                current_count = len(json.load(f))
            except: pass

    while current_count < TARGET_COUNT:
        doc_id, chunk = load_random_chunk()
        if not chunk:
            continue

        # æå–å±•ç¤ºä¿¡æ¯
        jurisdiction = chunk.get('jurisdiction', 'UNKNOWN').upper()
        summary = chunk.get('summary', 'æ— æ‘˜è¦')
        text = chunk.get('text', '') # å±•ç¤ºåŸå§‹æ–‡æœ¬ï¼Œé˜…è¯»ä½“éªŒæ›´å¥½
        
        print(f"\nğŸ“š è¿›åº¦: [{current_count + 1}/{TARGET_COUNT}] | æ³•åŸŸ: {jurisdiction} | æ–‡æ¡£: {doc_id}")
        print("-" * 60)
        print(f"ğŸ“„ã€æ–‡æ¡£æŒ‡çº¹/æ‘˜è¦ã€‘:\n{summary[:150]}...")
        print("-" * 30)
        print(f"ğŸ“ã€æ³•å¾‹æ¡æ–‡ç‰‡æ®µã€‘:\n{text[:800]} ...") 
        print("-" * 60)

        # è·å–ç”¨æˆ·è¾“å…¥
        question = input("ğŸ‘‰ è¯·è¾“å…¥åŸºäºæ­¤æ®µè½çš„é—®é¢˜ (s=è·³è¿‡, q=é€€å‡º): ").strip()

        if question.lower() == 'q':
            print("\nğŸ’¾ è¿›åº¦å·²ä¿å­˜ã€‚å†è§ï¼")
            break
        if question.lower() == 's' or question == "":
            print("â­ï¸  å·²è·³è¿‡...")
            continue

        # è‡ªåŠ¨æ„å»ºæ•°æ®ç»“æ„
        # ç®€å•æ¨æ–­è¯­è¨€ï¼šå¦‚æœæ³•åŸŸæ˜¯ CN è®¾ä¸º zhï¼Œå¦åˆ™è®¾ä¸º en (å¯æ‰‹åŠ¨æ”¹)
        lang = "zh" if jurisdiction == "CN" else "en"
        
        new_entry = {
            "id": f"MANUAL_{current_count+1:02d}",
            "question_text": question,
            "question_language": lang, 
            "target_jurisdictions": [jurisdiction],
            "topic_category": "general", # ç¨åå¯ä»¥æ‰‹åŠ¨ç»†åŒ–
            "gold_sources": [
                {
                    "citation": doc_id, # å…³é”®ï¼ç›´æ¥ä½¿ç”¨æ–‡ä»¶åä½œä¸ºå¼•ç”¨ï¼ŒDRM ç»å¯¹åŒ¹é…
                    "jurisdiction": jurisdiction,
                    "relevance_note": "Human curated ground truth."
                }
            ],
            # ä¿ç•™æºåˆ‡ç‰‡ä¿¡æ¯æ–¹ä¾¿å¤æŸ¥
            "source_chunk_preview": text[:50] 
        }

        save_entry(new_entry, OUTPUT_FILE)
        current_count += 1
        print(f"âœ… ç¬¬ {current_count} é¢˜å·²å½•å…¥ï¼")

    if current_count >= TARGET_COUNT:
        print(f"\nğŸ‰ æ­å–œï¼{TARGET_COUNT} é¢˜ç›®æ ‡å·²è¾¾æˆï¼æ–‡ä»¶ä¿å­˜åœ¨: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
